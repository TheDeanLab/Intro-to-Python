{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a50f53",
   "metadata": {},
   "source": [
    "## Python Library Ecosystem Exercise: Parsing, Manipulating, and Exploring Patient Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca9616",
   "metadata": {},
   "source": [
    "We are going to revisit the same public dataset of COVID-19 chest x-ray images as before. Now, instead of writing loops and iterating one-by-one over data entries, we are going to make use of python libraries and save ourselves a lot of coding and even gain speed!\n",
    "\n",
    "To start, let's make sure the libraries are installed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a725fb",
   "metadata": {},
   "source": [
    "### Install Libraries\n",
    "\n",
    "Open a command prompt or terminal and use `pip` to install the libraries.\n",
    "```python\n",
    "pip install numpy scipy matplotlib pandas scikit-image scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e7211",
   "metadata": {},
   "source": [
    "Check these libraries are installed, either by printing the installed list of libraries:\n",
    "\n",
    "```python\n",
    "pip list\n",
    "```\n",
    "\n",
    "or open python in the terminal and attempt to import each one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6137087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported,  numpy\n",
      "imported,  scipy\n",
      "imported,  matplotlib\n",
      "imported,  pandas\n",
      "imported,  skimage\n",
      "imported,  sklearn\n"
     ]
    }
   ],
   "source": [
    "import importlib # this is only to import libraries in a loop by name. You would normally use 'import numpy' etc.\n",
    "\n",
    "library_names = ['numpy', 'scipy', 'matplotlib', 'pandas', 'skimage', 'sklearn']\n",
    "\n",
    "for lib in library_names:\n",
    "    try:\n",
    "        importlib.import_module(lib)\n",
    "        print('imported, ', lib)\n",
    "    except:\n",
    "        print(lib, ' library not installed ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7d6485",
   "metadata": {},
   "source": [
    "## 1. Read in the metadata.csv using ```pandas```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d902d364",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../datasets/covid-chestxray-dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# let's list the contents of the dataset repository\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[1;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datasets/covid-chestxray-dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../datasets/covid-chestxray-dataset'"
     ]
    }
   ],
   "source": [
    "# let's list the contents of the dataset repository\n",
    "import os \n",
    "\n",
    "os.listdir('../datasets/covid-chestxray-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258318d",
   "metadata": {},
   "source": [
    "As before, use a variable to store the dataset folder and construct filepath to metadata programmatically to help readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = '../datasets/covid-chestxray-dataset'\n",
    "metadata_file = os.path.join(dataset_folder,\n",
    "                            'metadata.csv')\n",
    "print(metadata_file) # Note the \\ if on Windows. It looks weird, but will work fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba89f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_read_csv(filepath):\n",
    "    import pandas as pd # recommended to place import in function definition if you are not using it for many functions\n",
    "    \n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "metadata_table = pandas_read_csv(metadata_file)\n",
    "\n",
    "# you will see the data is nicely formatted now on print and 'NaN' is used for empty entries\n",
    "print(metadata_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332de098",
   "metadata": {},
   "source": [
    "This structure makes it super easy to access contents. For example, the column names are keys. We can directly pull out all entries in the `patientid` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c980450",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = metadata_table.loc[:,'patientid':] # : denotes i want all.\n",
    "\n",
    "print(col_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b59a56",
   "metadata": {},
   "source": [
    "### Indexing and slicing the table by rows, or columns \n",
    "\n",
    "`pandas.DataFrame` can be subset by row or columns using `.loc` (by logic or string) or `.iloc` (by numerical index) methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # re-import to make it available globally\n",
    "\n",
    "# we can subset the first columns, from 'patientid' (1st column, index 0) up to 'RT_PCR_positive' (6th column, index 5) inclusive\n",
    "subset_col_table_by_column_name = metadata_table.loc[:,'patientid':'RT_PCR_positive'] # subset by string\n",
    "subset_col_table_by_column_index = metadata_table.iloc[:,0:6] # subset by string\n",
    "\n",
    "print(subset_col_table_by_column_name) # note this looks table-like however a column is 1D and therefore a pandas.Series\n",
    "print('==============================')\n",
    "print(subset_col_table_by_column_index)\n",
    "print('==============================')\n",
    "\n",
    "# Let's find all rows associated with patientid=2\n",
    "subset_patientid_2_data = metadata_table.loc[metadata_table['patientid'].values=='479']\n",
    "subset_col_subset_patientid_2_data = subset_col_table_by_column_index.loc[metadata_table['patientid'].values=='479']\n",
    "\n",
    "print('++++++++++++++++++++++++++++++')\n",
    "print(subset_patientid_2_data)\n",
    "print('++++++++++++++++++++++++++++++')\n",
    "print(subset_col_subset_patientid_2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900dc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful after subsetting by row if doing it by name, this is because the row index doesn't change!, so the name is that of the original!\n",
    "\n",
    "print('subsetting by index works')\n",
    "print(subset_col_subset_patientid_2_data.iloc[0])\n",
    "\n",
    "print('=================================')\n",
    "print('=================================')\n",
    "print('subsetting by name must use the name in original table, else you will get keyerror')\n",
    "print(subset_col_subset_patientid_2_data.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c25c2",
   "metadata": {},
   "source": [
    "There are some quirks for working directly with `pandas.Series`, `pandas.DataFrame` and performing mathematical or plotting operations using e.g. `numpy` and `matplotlib`. Therefore it is valuable to know how to convert to pure `numpy` arrays. The downside is that we lose the associated row and columns information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc5f6f",
   "metadata": {},
   "source": [
    "### Let's compare Pandas vs Our Pure Python naive line-by-line csv reading code\n",
    "\n",
    "First let's define a function for the previous line-by-line reading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_line_by_line(filepath):\n",
    "    \n",
    "    metadata_contents = []\n",
    "\n",
    "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f: # note the for loop iteration.\n",
    "            # strip blank space, split by comma\n",
    "            line_contents = line.strip().split(',')\n",
    "            # append into empty list\n",
    "            metadata_contents.append(line_contents)\n",
    "\n",
    "    return metadata_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666c54d",
   "metadata": {},
   "source": [
    "We use the `time` function from the `time` python module to time both approaches to reading the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# first time pandas\n",
    "t1_pandas = time.time() # start the clock\n",
    "metadata_table_pandas = pandas_read_csv(metadata_file) \n",
    "t2_pandas = time.time() # stop the clock\n",
    "print('pandas reading time: ', t2_pandas-t1_pandas)\n",
    "\n",
    "# second time pure python line-by-line\n",
    "t1_python = time.time()\n",
    "metadata_table_python = read_csv_line_by_line(metadata_file)\n",
    "t2_python = time.time()\n",
    "print('python reading time: ', t2_python-t1_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ff97f",
   "metadata": {},
   "source": [
    "**Wow! pure python was faster than pandas!** This is a little bit of a warning. Library does not equal fast. A single function may be hiding many steps underneath which slow-down the code. \n",
    "\n",
    "Our test here was a little unfair, since we don't return an array. Let's use numpy to revise the line-by-line code to return the column names and an array of values, which is effectively what pandas offers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434916c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_line_by_line_numpy(filepath):\n",
    "    import numpy as np\n",
    "    \n",
    "    metadata_contents = []\n",
    "\n",
    "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f: # note the for loop iteration.\n",
    "            # strip blank space, split by comma\n",
    "            line_contents = line.strip().split(',')\n",
    "            # append into empty list\n",
    "            metadata_contents.append(line_contents)\n",
    "    columns = np.hstack(metadata_contents[0]) # this is the first line of file, and we use np.hstack to turn into 1D array\n",
    "    data = np.array(metadata_contents[1:],dtype=object) # we use np.array to convert the rest to numpy array\n",
    "\n",
    "    return data, columns # note we return two things now.\n",
    "\n",
    "# third time pure python line-by-line with numpy array conversion\n",
    "t1_python_numpy = time.time()\n",
    "metadata_table_numpy, metadata_table_columns = read_csv_line_by_line_numpy(metadata_file)\n",
    "t2_python_numpy = time.time()\n",
    "\n",
    "print('pandas reading time: ', t2_pandas-t1_pandas)\n",
    "print('python reading time: ', t2_python-t1_python)\n",
    "print('python + numpy conversion reading time: ', t2_python_numpy-t1_python_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b037cda9",
   "metadata": {},
   "source": [
    "python + numpy conversion is still faster! but there is a problem. We have a warning of ragged nested sequences. This is not good. A table should be a regular n_rows x n_cols matrix. \n",
    "\n",
    "We check the shape of the numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b85e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('python + numpy data shape', metadata_table_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b93490",
   "metadata": {},
   "source": [
    "This is 1-dimensional when it should be 2!\n",
    "\n",
    "What's the problem? It is because our code is splitting each line by looking for commans ','. However, the comma is not exclusively separating columns. Some column entries such as `data`, and `clinical_notes` contain ',' in their text! \n",
    "\n",
    "`pandas` was able to correctly read the table as it incorporates proof-checking, based on the expected number of columns, parsed from the first line. We need to write much more code to detect and correct for the extra commas. This is generally not worth it and we might not get it right! More general handling and treatment of potential errors is why even though it may be slower, it is better practice to use a well-developed library.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c6458",
   "metadata": {},
   "source": [
    "You will now write control statements using the metadata_contents list :\n",
    "\n",
    "Try to do as many as you can - you can team up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c0ffa",
   "metadata": {},
   "source": [
    "## 2. Getting the data we want from the metadata table, now using library functions\n",
    "\n",
    "We can revisit the exercises you previously did with loops and replace them. We can also start viewing the associated images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9c0f4",
   "metadata": {},
   "source": [
    "#### Exercise 1: Create an array for `patientid` from `metadata_table`. Hint: answer already given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecbdd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77551d8f",
   "metadata": {},
   "source": [
    "#### Exercise 2: Find the number of unique `patientid` as well as the unique ids . Hint: `numpy.unique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e02fee",
   "metadata": {},
   "source": [
    "#### Exercise 3: Find the `age` of each unique `patientid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57278c55",
   "metadata": {},
   "source": [
    "#### Exercise 4: Find the `finding` of each unique `patientid`. How many unique `finding` are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aed1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4592e869",
   "metadata": {},
   "source": [
    "## 3. Exploring and visualizing the data\n",
    "\n",
    "We can use the various libraries to make plots, and explore the data further to get some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642c427",
   "metadata": {},
   "source": [
    "####  Exercise 5: Plot a histogram of `age` using matplotlib. You can import matplotlib with `import pylab as plt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ebbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80969f41",
   "metadata": {},
   "source": [
    "####  Exercise 6: Find the ages of patients for each unique `finding`. How many patients are there in each? Make a boxplot using `matplotlib`. Use `scipy.stats.ttest_ind` to perform an unpaired t-test to test for age differences in two of the unique findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef24ee0",
   "metadata": {},
   "source": [
    "####  Exercise 7: Write code to find the image path/s associated with each unique patient. Use `scikit-image` to read and `matplotlib` to display them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n",
    "# HINT: the associated images are found in the 'folder' and 'filename' columns. \n",
    "# There are multiple image files per patient id. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cea204",
   "metadata": {},
   "source": [
    "## Extension: Relating images and metadata to disease variables\n",
    "\n",
    "The key objective of data analysis particularly in the medical domain is to understand potential parameters related to disease. For this dataset, we have available in `annotations` folder provided covid severity scores for a subset of images. This is described in the paper, https://arxiv.org/pdf/2005.11856.\n",
    "\n",
    "You will load this file in as a data table, matching the contents to their respective image files to perform some analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbab25",
   "metadata": {},
   "source": [
    "#### Extension exercise 1: (Read in covid severity score and match with file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbefb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file path is the following\n",
    "covid_severity_score_file = os.path.join(dataset_folder, \n",
    "                                        'annotations',\n",
    "                                        'covid-severity-scores.csv')\n",
    "\n",
    "# a) take a look at this file in excel or equivalent. Is this in the format of the table? How would you try to read it in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Note there is a 'filename' column in this table, There is also another in the master metadata_table we had read in. How could we combine the two tables? \n",
    "# HINT: pandas.merge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) check these patients are all covid19, check the uniqueness of patient with respect to number of rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Is there a relationship between the 2 severity scores? - you can answer with a plot. Is there a way you can quantify the degree of correlation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb55879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e) is there a relationship between covid severity and age?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f) is there a relationship between covid severity and sex?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c4f29d",
   "metadata": {},
   "source": [
    "#### Let's try to play a little with images, with the tools we have. \n",
    "\n",
    "Generally, working directly on individual pixel intensity is not very informative. Consequently, features are extracted from images to form a vector per image which is then input to machine learning algorithms. This is basically what a neural network does. Here we will just explore this a little using the tools available in scikit-image and scikit-learn, just to give you an idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708b2b9",
   "metadata": {},
   "source": [
    "#### Extension exercise 2: (PCA on raw image intensities) \n",
    "Read in each image of the merged table using `scikit-image`. (what do you do if images are different size?). An image is 2-dimensional, you will then flatten the image into 1D vector to apply PCA to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f13e2f",
   "metadata": {},
   "source": [
    "#### Extension exercise 3: (Train a binary SVM classifier to predict covid severity based on image)\n",
    "\n",
    "From the PCA it looks like we might be able to binary separate hi and low severity from image intensity. Therefore lets do the following:\n",
    "\n",
    "1) plot a histogram of severity score and choose a cutoff to designate 'high' = 1 and 'low' = 0\n",
    "2) split the data into 50-50 train-test, using 50% to fit the SVM, and the other 50% to test performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code in here, or else use your favorite Python IDE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to:\n",
    "\n",
    "# 2a) split the data into 50-50 train-test. Hint: sklearn.model_selection.train_test_split function \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:u_Segment3D_env]",
   "language": "python",
   "name": "conda-env-u_Segment3D_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
