{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scientific Computing with Python: Getting familiar with ```numpy```, ```scipy``` and ```scikit-learn``` for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Manipulating an image with ```scikit-image```\n",
    "\n",
    "Load the Immunohistochemistry (IHC) example image stored in `im_path`. We are going to try and extract the blue-stained cell nuclei and then perform a crude binary segmentation on them. This is a very typical problem in cell biology image processing.\n",
    "\n",
    "We have included all the required imports from `skimage` that you should need. The steps are as follows:\n",
    "\n",
    "1. Perform a color unmixing to get the Haematoxylin-Eosin-DAB (HED) channels, and store the image containing the nuclei in a variable.\n",
    "1. Do a gaussian blurring to ensure smooth boundaries for our segmentation.\n",
    "1. Apply an Otsu threshold to segment based on the image intensities, producing a binary image. You will need to use some [comparison operator](https://www.w3schools.com/python/gloss_python_comparison_operators.asp), can you guess which one?\n",
    "1. Plot your final `nuclei_mask` using `pyplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = \"../datasets/images/ihc.png\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2hed\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "\n",
    "# load the image using the appropriate function. call it \"im\"\n",
    "im = ...\n",
    "\n",
    "# --- uncomment to plot ---\n",
    "# plt.imshow(im)\n",
    "# -------------------------\n",
    "\n",
    "# perform RGB to Haematoxylin-Eosin-DAB (HED) color unmixing\n",
    "\n",
    "# take only the nuclei channel and store it in a variable \"nuclei\"\n",
    "\n",
    "# blur the nuclei\n",
    "\n",
    "# apply an otsu threshold to create a binary mask. call the binary image \"nuclei_mask\"\n",
    "nuclei_mask = ...\n",
    "\n",
    "# --- uncomment to plot ---\n",
    "# plt.figure()\n",
    "# plt.imshow(nuclei_mask)\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Statistical analysis with `scipy`\n",
    "\n",
    "Here we have loaded the <b>Iris dataset</b> from <a href=\"https://scikit-learn.org/1.5/datasets/toy_dataset.html\">scikit-learn</a>. The data is loaded in a machine-learning friendly format: ```pd.DataFrame```. We view the first few entries using ```df.head()```. You will use this data to explore the power of `scipy` for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2\n",
       "0  True  False  False\n",
       "1  True  False  False\n",
       "2  True  False  False\n",
       "3  True  False  False\n",
       "4  True  False  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load the data\n",
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "# one-hot encode\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2.1: Summarize your data statistics.\n",
    "\n",
    "Use either ```numpy```, ```scipy``` or ```pandas``` to statistically summarize the classes in your data by computing the `mean` and `standard deviation`. Do it for all features, if there is more than one. Summarize the results in a ```pd.DataFrame```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "means = []\n",
    "stds = []\n",
    "\n",
    "# here, write some code to take the .mean and .std of all of your X data\n",
    "# store in \"means\" and \"stds\"\n",
    "\n",
    "\n",
    "# means\n",
    "display(pd.DataFrame(means))\n",
    "\n",
    "# standard deviations\n",
    "display(pd.DataFrame(stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2.2: Perform a significance test using your dataset.\n",
    "\n",
    "Choose an interesting feature from your dataset and use ```scipy``` to perform a signicance test to determine if there is a significant difference between your classes/targets. For bonus points, select a good plot from ```seaborn``` and visualize the data.\n",
    "\n",
    "We have chosen a test for you in the `imports`... Why did we chose this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure ... is a key in X?\n",
      "Ellipsis\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# look at your stats to select a feature which you think could demonstrate a significant difference between flowers\n",
    "feature = \"...\"\n",
    "\n",
    "# preparing the 3 datasets to use in our test for the selected feature \n",
    "try:\n",
    "    v0 = X[feature].values[y[0]]\n",
    "    v1 = X[feature].values[y[1]]\n",
    "    v2 = X[feature].values[y[2]]\n",
    "except KeyError:\n",
    "    print(f\"Are you sure {feature} is a key in X?\")\n",
    "\n",
    "# plotting our data. what do you think will be the result of our test?\n",
    "try:\n",
    "    sns.violinplot(data=[v0, v1, v2], inner='point')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# perform the statistical test here:\n",
    "result = ...\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use Machine Learning in `scikit-learn` to do a Binary Classification\n",
    "\n",
    "Binary Classifications are classifications with only two classes as targets: True/False, Positive/Negative, Malignant/Benign, etc. \n",
    "\n",
    "We have loaded the <b>Breast cancer wisconsin (diagnostic) dataset</b> from ```scikit-learn``` as a good example. This dataset is more intereting than Iris from a Machine Learning perspective, as it has a binary class output of malignant/benign and a decent number of patients and features for us to work with.\n",
    "\n",
    "Following convention, **Features** and **Targets** are stored in the variables `X` and `y`, respectively. You will use these as inputs/outputs for your ML model. We will do some <b>data visualization</b>: a critical step in ML to determine if classes even exist in your high dimensional data. Finally, we do proper train/test splitting to test how good your model performs in predicting malignant/benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# load the data\n",
    "dataset = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1: Visualize the data using Dimensionality Reduction\n",
    "\n",
    "Data visualization is critical to determining how to move forward in any machine learning task. However, high-dimensional data like we have here is difficult, if not impossible, to visualize. \n",
    "\n",
    "Below we have taken our high-dimensional data and reduced it to 2-dimensions using <a href=\"https://scikit-learn.org/dev/modules/generated/sklearn.decomposition.PCA.html\">Principle Component Analysis (PCA)</a>. If we plot the result and label based on our known targets, we can see if two groups exist within the data or not. Run the code: does it look like a nice binary classification problem, or not?\n",
    "\n",
    "PCA is kind of outdated, and isn't the best method for visualizing clusters. A more modern technique is <a href=\"https://scikit-learn.org/0.16/modules/generated/sklearn.manifold.TSNE.html\">t-distributed Stochastic Neighbor Embedding (tSNE)</a>.\n",
    "\n",
    "Implement tSNE to reduce the data to 2-dimensions. How does our outlook for binary classification look now?\n",
    "\n",
    "#### Do you think there exists, somewhere in your data, two distinct classes that an ML model can suss out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA for n_components=2 on X\n",
    "# store the result in small x\n",
    "\n",
    "x_pca = ...\n",
    "\n",
    "# plotting our data. Is there class separation?\n",
    "try:\n",
    "    sns.scatterplot(x=x_pca[:, 0], y=x_pca[:, 1], markers='.', c=y)\n",
    "    plt.title(\"PCA\")\n",
    "except TypeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Perform tSNE on our data using X with n_components=2 and perplexity=30.0\n",
    "# store the result in x_tsne\n",
    "\n",
    "x_tsne = ...\n",
    "\n",
    "# plotting our data. Is there class separation now?\n",
    "# what if you change the perplexity?\n",
    "try:\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=x_tsne[:, 0], y=x_tsne[:, 1], markers='.', c=y)\n",
    "    plt.title(\"tSNE\")\n",
    "except TypeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2: Perform a Train/Test Split of your Data\n",
    "\n",
    "A critical preparation step for supervised machine learning, Train/Test splitting allows us to reserve a \"hold-out\" Test set which our model will not be trained on. This allows us to determine if our model is <b>overfitting</b> or learning the training dataset too well, preventing it from generalizing to new, unseen data.\n",
    "\n",
    "<b>Train/Test split at a ratio of 80/20.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# use the imported function to do the train/test split here\n",
    "try:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "except TypeError:\n",
    "    pass\n",
    "else:\n",
    "    # Afterwards, we apply data normalization so it will work with our ML model\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3: Fit a Binary Classification model to your Data, and make predictions.\n",
    "\n",
    "We will now \"fit\" our data to a binary classification model. For convenience, we have selected an appropriate model which you may recognize from the slides. However, you don't have to use this one if you think there may be a better one! As always, [dig into the docs](https://scikit-learn.org/1.5/supervised_learning.html)!\n",
    "\n",
    "Begin by creating your model, which is a class `LogisticRegression`, and then call the `.fit` and `.predict` methods respectively. Refer to the slides for an example of how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create the model and run model.fit\n",
    "model = ...\n",
    "\n",
    "# make predictions y_pred using model.predict\n",
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.4: Evaluate your model performance. How did it do?\n",
    "\n",
    "You can fit any model to any dataset, but it doesn't mean that it will make correct predictions. That is why we made our \"hold-out\" set, (`X_test`, `y_test`).\n",
    "\n",
    "For binary classifications, you can use something called a [confusion matrix](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.confusion_matrix.html). It compares the predicted binary values to the true binary values. The diagonals of the matrix will thus be True Negatives and True Positives, and the anti-diagonals will be False Negatives and False Positives ([more info](https://en.wikipedia.org/wiki/Confusion_matrix)). A good model will have very high values on the diagonals, and very low values on the off-diagonals.\n",
    "\n",
    "Create the `confusion_matrix` using the imported function, and plot it using `seaborn.heatmap`. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = ...\n",
    "\n",
    "# plot using heatmap\n",
    "try:\n",
    "    heatmap(cm, annot=True)\n",
    "except ValueError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
