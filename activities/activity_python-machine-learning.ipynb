{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scientific Computing with Python: Getting familiar with machine learning with ```sklearn```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use Machine Learning in `scikit-learn` to do a Binary Classification\n",
    "\n",
    "Binary Classifications are classifications with only two classes as targets: True/False, Positive/Negative, Malignant/Benign, etc. \n",
    "\n",
    "We have loaded the <b>Breast cancer wisconsin (diagnostic) dataset</b> from ```scikit-learn``` as a good example. This dataset is more intereting than Iris from a Machine Learning perspective, as it has a binary class output of malignant/benign and a decent number of patients and features for us to work with.\n",
    "\n",
    "Following convention, **Features** and **Targets** are stored in the variables `X` and `y`, respectively. You will use these as inputs/outputs for your ML model. We will do some <b>data visualization</b>: a critical step in ML to determine if classes even exist in your high dimensional data. Finally, we do proper train/test splitting to test how good your model performs in predicting malignant/benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# load the data\n",
    "dataset = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1: Visualize the data using Dimensionality Reduction\n",
    "\n",
    "Data visualization is critical to determining how to move forward in any machine learning task. However, high-dimensional data like we have here is difficult, if not impossible, to visualize. \n",
    "\n",
    "Below we have taken our high-dimensional data and reduced it to 2-dimensions using <a href=\"https://scikit-learn.org/dev/modules/generated/sklearn.decomposition.PCA.html\">Principle Component Analysis (PCA)</a>. If we plot the result and label based on our known targets, we can see if two groups exist within the data or not. Run the code: does it look like a nice binary classification problem, or not?\n",
    "\n",
    "PCA is kind of outdated, and isn't the best method for visualizing clusters. A more modern technique is <a href=\"https://scikit-learn.org/0.16/modules/generated/sklearn.manifold.TSNE.html\">t-distributed Stochastic Neighbor Embedding (tSNE)</a>.\n",
    "\n",
    "Implement tSNE to reduce the data to 2-dimensions. How does our outlook for binary classification look now?\n",
    "\n",
    "#### Do you think there exists, somewhere in your data, two distinct classes that an ML model can suss out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA for n_components=2 on X\n",
    "# store the result in small x\n",
    "\n",
    "x_pca = ...\n",
    "\n",
    "# plotting our data. Is there class separation?\n",
    "try:\n",
    "    sns.scatterplot(x=x_pca[:, 0], y=x_pca[:, 1], markers='.', c=y)\n",
    "    plt.title(\"PCA\")\n",
    "except TypeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Perform tSNE on our data using X with n_components=2 and perplexity=30.0\n",
    "# store the result in x_tsne\n",
    "\n",
    "x_tsne = ...\n",
    "\n",
    "# plotting our data. Is there class separation now?\n",
    "# what if you change the perplexity?\n",
    "try:\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=x_tsne[:, 0], y=x_tsne[:, 1], markers='.', c=y)\n",
    "    plt.title(\"tSNE\")\n",
    "except TypeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: Perform a Train/Test Split of your Data\n",
    "\n",
    "A critical preparation step for supervised machine learning, Train/Test splitting allows us to reserve a \"hold-out\" Test set which our model will not be trained on. This allows us to determine if our model is <b>overfitting</b> or learning the training dataset too well, preventing it from generalizing to new, unseen data.\n",
    "\n",
    "<b>Train/Test split at a ratio of 80/20.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# use the imported function to do the train/test split here\n",
    "try:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "except TypeError:\n",
    "    pass\n",
    "else:\n",
    "    # Afterwards, we apply data normalization so it will work with our ML model\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3: Fit a Binary Classification model to your Data, and make predictions.\n",
    "\n",
    "We will now \"fit\" our data to a binary classification model. For convenience, we have selected an appropriate model which you may recognize from the slides. However, you don't have to use this one if you think there may be a better one! As always, [dig into the docs](https://scikit-learn.org/1.5/supervised_learning.html)!\n",
    "\n",
    "Begin by creating your model, which is a class `LogisticRegression`, and then call the `.fit` and `.predict` methods respectively. Refer to the slides for an example of how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create the model and run model.fit\n",
    "model = ...\n",
    "\n",
    "# make predictions y_pred using model.predict\n",
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4: Evaluate your model performance. How did it do?\n",
    "\n",
    "You can fit any model to any dataset, but it doesn't mean that it will make correct predictions. That is why we made our \"hold-out\" set, (`X_test`, `y_test`).\n",
    "\n",
    "For binary classifications, you can use something called a [confusion matrix](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.confusion_matrix.html). It compares the predicted binary values to the true binary values. The diagonals of the matrix will thus be True Negatives and True Positives, and the anti-diagonals will be False Negatives and False Positives ([more info](https://en.wikipedia.org/wiki/Confusion_matrix)). A good model will have very high values on the diagonals, and very low values on the off-diagonals.\n",
    "\n",
    "Create the `confusion_matrix` using the imported function, and plot it using `seaborn.heatmap`. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = ...\n",
    "\n",
    "# plot using heatmap\n",
    "try:\n",
    "    heatmap(cm, annot=True)\n",
    "except ValueError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
